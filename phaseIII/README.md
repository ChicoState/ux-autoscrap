# Phase III: Prototypes and User Testing

## Introduction

Autoscrap™ is an app designed to help people who are in need of a car part for the cheapest possible price. This app will also help those who have parts to sell move inventory with ease and maintain an online listing for any parts they have to sell. So the users are buyers and sellers alike and will hopefully have their interests met with our app.  In this Phase, we use our prototype as a faux website to test our design on actual users to see how we can improve our final prototype.

## Methods

The AutoScrap Usability Engineering team conducted usability tests with users on May 7th, 2024 (n = 7). Our UX team first created a working Prototype of our product from our wireframes. The next steps we took were to create a protocol/script for the Pilot test, generate an Informed Consent Form, and finally submit an IRB form to make our Pilot tests official. Our protocol for the Pilot test includes background information questions, tasks for the user to complete on our application, and a debrief section for feedback to close it out.  

Our group focused on a more formative approach when it came to designing our protocol. Things like what usability issues exist in our product and does the user understands our navigation were what our researchers were looking for during testing. We also implemented a think-aloud approach for the users when doing the tasks so we could get more information on how they approached each task. The current moderator for each Pilot test would take notes on how the user approached each task and any issues that occurred.  

The 7 participants were other student UX researchers from our class. We had a requirement for each participant to be over the age of 18.  

At the beginning of our Pilot test protocol, we asked each participant a few background questions. The first question “What kind of car do you own?” would help us interpret the data we receive from them during the process. If the answer to the previous question was yes, the second question would be “Have you ever bought a used car part before?” This question would help us see if the user had previous experience with something similar to what our product has to offer. Question three was then “If so, where was it bought from and how easy was it to get?” This question focused on competitors and the user’s experience with their overall product usability. Our final question was “Was there anything that could have been improved?” This question’s purpose was to see if there were any glaring issues or missing features in our competitors that our product could take advantage of.  

The next step of our Pilot test would test our prototype by having the participant do four separate tasks. We asked the user to explain their thought process while doing each task. We also kept track of whether or not they completed each task and asked them to rate it on a scale of 1 to 5 with 1 being very hard and 5 being very easy. 
The first task was “Imagine that your Ford Bronco broke down and needs a new set of spark plugs. You have a budget of $500 to use on bidding for it. Walk through the steps you would take to find the car part and place a bid within the given budget.” This task focused on seeing how usable our search bar and filters were when finding a specific car part. The user would then have to place a bid which would be on the details page of the filtered car part listing. A key aspect was seeing if the user used both the search and filter and whether one was used together or sequentially. This process is the crux of our product and seeing its usability is paramount.  

The second task was “Imagine you inherited a 2020 GMC Terrain from your long lost uncle and now you need some money. Walk me through the steps you would take to create a listing of a part of the car on the site.” This task focused on our product’s ability to have users create listings for used car parts. We wanted to see if users could easily find where to create a part listing. 
The third task was “You want to add your 2021 Ford Bronco with a V6 engine to help narrow down your searches. How would you go about doing that?” While similar to the first task, this one was focused on our saved car feature. This feature allowed users to input aspects of the car like make, model, engine, and year and have it be like a more permanent filter. Finding a car part that fits your exact car is tough so having a way to filter down to one specific kind is very useful.  

Our final task was “Imagine that an hour has passed and you want to see if someone has outbid you on the spark plugs you wanted to get. Explain how you would go about checking whether you have been outbid or not and if you have, make a new higher bid on the car part.” This last task focused on our profile page which held information about a user’s listings and bids. This page would detail their bids alongside the time left, the price they bid at, and the current price which could be something higher. Our product is essentially an auction site for used car parts so being able to see if you have been outbid or not is a key feature that needs to work.  

The last part of the Pilot test was a debriefing. We first asked “What did you like best?” to find out what feature stood out the most as helpful for the user. The next question was “Anything stand out as unintuitive or not clear when finding or bidding for a part?” This question was to find anything off or missing when it came to the core loop of our product with searching for used car parts. Afterward, we followed that up with “Anything else that could be improved?”. This question is broader in scope allowing for suggestions in any other aspect of our product like profile pages or details. Our final question was “What other features would you like to see on our platform?” This question would help us find any other features that would be good to implement. These features could be from competitors or other similar products that we have either missed or not thought about.  


## Findings

Using our protocol we ran a study using participants from class(n = 7). After transferring the data into a [spreadsheet](https://github.com/ChicoState/ux-autoscrap/blob/main/phaseIII/AutoScrap%20User%20Test%20Data.pdf) we were able to make quite a few discoveries about our product as well as the prototype's usability.  

Concerning our background questions, we found that 5 of our participants had bought used car parts before. Some had bought in person at a store or junkyard while some bought on online storefronts like eBay. Some concerns they had were clearer photos of the parts and better details on part compatibility. These issues focused on making sure the part in question fits the user’s car.  

For the first task, it seemed that all of the users were able to find the spark plugs with the search bar and filters fairly easily. Many of them filled out all the filters which inadvertently also finished what we wanted from task 3. They were all able to navigate to a details page and make a bid on a car part. Some tried to search without logging in but most logged in first before searching. All users were able to complete this task.  

For the second task, most of the users were able to go to the profile page and find the + button near the bottom of the user’s listing column. The actual process of filling in the listing information and creating the listing was done easily by all. There were some concerns about having a dedicated listing and bids tab instead of a profile page as users associated a profile page with other information. Aside from that, all users were able to complete the task.  

This third task of ours ended up being a bit redundant in its usage. This task’s purpose of using the ‘add vehicle’ feature to narrow searches needed all 5 of the filters to be filled in which most ended up doing for the first task. Filling in the filters and hitting either search or add vehicle went to the same place so that could be something we could change in the future. This overlapped process could have been better worded or just added to the first task. Regardless of that, the task was still completed by all users.  

The fourth task went smoothly for most of the participants. Many of the participants briefly saw their previous bid on the profile page when they went to create a listing for task 2 and as such had an idea of how to complete the task. They were able to check the difference in the current bid to theirs and then place a new higher bid. All of the users were able to complete the task.  

For the debrief section, the most common praise of the product was for the filtering system and how easy the product was to use. The process for searching and bidding was easy for most of the users. The most common improvement that was suggested was separate tabs on the main page for a user’s bids and listings. Having those two things in the profile seemed unintuitive for a good amount of the users. Finally, we had suggestions for new features like user reviews, complete car listings, motorcycle parts, and favorite listings tab.  

Overall, all tasks were completed by all of our users. The majority of the users found the tasks to be fairly easy to complete. Below is a graph that shows the average rating of each task on a scale of 1 to 5:  
![Task Difficulty Rating (Average)](https://github.com/ChicoState/ux-autoscrap/assets/111708782/c6852b78-94de-42b2-9aca-43eee990a5b3)

## Conclusions

Our findings from the usability tests revealed that users generally found the task easy to complete and received positive feedback on our filtering system that we implemented on our application. However, there are several things that our application still needs to be improved on. First of all, users expressed their desire to add some sort of search history or the ability to add a vehicle as favorites so they wouldn’t retype their car information multiple times. To address this, we would aim to further enhance our search functionality by implementing a predictive text to auto refill their car information faster and add a favorites tab so it could be more convenient for our users to resume or search other parts with the same car. Another issue is our bidding and listing tabs weren’t visually clear and some of our users were confused on how to navigate to those destinations. To eliminate this issue, we would redesign the profile page so it could be more clear for users and add more visual cues to guide our users. Lastly, we will pritioze implementing user requested features such as user reviews so our users feel more confident about their purchase, parts for motorcycles to gain more users onto our platform, and separate tabs to enhance overall user satisfaction. By continuously monitoring user interactions and behavior within our platform, it will help us improve our app effectively to meet user needs. 

## Caveats

It's essential to recognize some key considerations and limitations regarding the methods we utilized and the findings we gathered from our research. First of all, the limited number of users involved could impact our results. Additionally, some users may have limited knowledge about cars which could potentially affect our results since the participant’s lack of car knowledge might hinder their ability to understand certain features or tasks. Furthermore, participants may bring biases or prior UX experience, given that they are also students which could influence their feedback. As students, they may possess a level of understanding or familiarity with UX concepts that differs from a typical user which could potentially mislead research. Moreover, it's important to note that our prototype may not fully represent the final app’s appearance and functionality. Certain features, interactions, or visual elements may be inaccurately depicted, which would impact our users' perceptions and feedback of our app. While our methods provided valuable insights, it's crucial to acknowledge these limitations and explore additional research methods to further improve our application.
